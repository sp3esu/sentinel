---
phase: 05-tool-calling
plan: 03
type: execute
wave: 2
depends_on: ["05-01", "05-02"]
files_modified:
  - src/native/streaming.rs
  - src/native_routes/chat.rs
  - tests/integration/native_chat.rs
  - tests/mocks/openai.rs
autonomous: true

must_haves:
  truths:
    - "Streaming tool call deltas accumulate correctly by index"
    - "Accumulated tool calls finalize with parsed JSON arguments"
    - "Handler integrates ID mapping for tool call responses"
    - "Integration tests verify end-to-end tool calling flow"
  artifacts:
    - path: "src/native/streaming.rs"
      provides: "ToolCallAccumulator for streaming"
      contains: "pub struct ToolCallAccumulator"
    - path: "src/native_routes/chat.rs"
      provides: "Handler updated for tool call translation"
      contains: "ToolCallIdMapping"
    - path: "tests/integration/native_chat.rs"
      provides: "Tool calling integration tests"
      contains: "test_tool_calls"
  key_links:
    - from: "src/native/streaming.rs"
      to: "src/native/types.rs"
      via: "ToolCall, ToolCallDelta imports"
      pattern: "use.*types::.*(ToolCall|ToolCallDelta)"
    - from: "src/native_routes/chat.rs"
      to: "src/native/translate"
      via: "ToolCallIdMapping usage"
      pattern: "ToolCallIdMapping"
---

<objective>
Implement streaming tool call accumulation and integrate tool calling into the chat handler with end-to-end tests.

Purpose: Complete the tool calling feature by handling streaming responses with tool calls (where deltas arrive incrementally) and ensuring the handler properly manages ID mappings. Integration tests verify the full flow works correctly.

Output: Working streaming tool calls with proper accumulation, handler integration, and comprehensive tests.
</objective>

<execution_context>
@/Users/gregor/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gregor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-tool-calling/05-CONTEXT.md
@.planning/phases/05-tool-calling/05-RESEARCH.md
@src/native/streaming.rs
@src/native_routes/chat.rs
@tests/integration/native_chat.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement ToolCallAccumulator for streaming</name>
  <files>src/native/streaming.rs</files>
  <action>
Add ToolCallAccumulator to handle streaming tool call deltas:

1. Add imports:
   ```rust
   use crate::native::types::{ToolCall, ToolCallFunction};
   use crate::native::response::ToolCallDelta;
   use std::collections::HashMap;
   ```

2. Add AccumulatedToolCall struct (internal):
   ```rust
   #[derive(Debug, Default)]
   struct AccumulatedToolCall {
       id: Option<String>,        // Provider ID from first delta
       function_name: String,     // Accumulated from deltas
       arguments: String,         // Accumulated argument string fragments
   }
   ```

3. Add ToolCallAccumulator:
   ```rust
   /// Accumulates tool call deltas across streaming chunks.
   ///
   /// OpenAI sends tool calls incrementally with `index` identifying which
   /// tool call in a parallel set is being updated. This accumulator tracks
   /// each tool call separately and finalizes them when streaming completes.
   #[derive(Debug, Default)]
   pub struct ToolCallAccumulator {
       /// Index -> accumulated tool call data
       tool_calls: HashMap<u32, AccumulatedToolCall>,
   }

   impl ToolCallAccumulator {
       pub fn new() -> Self { Self::default() }

       /// Process a streaming delta for tool calls.
       ///
       /// Call this for each ToolCallDelta received in a streaming chunk.
       pub fn accumulate(&mut self, delta: &ToolCallDelta) {
           let entry = self.tool_calls.entry(delta.index).or_default();

           if let Some(ref id) = delta.id {
               entry.id = Some(id.clone());
           }
           if let Some(ref func) = delta.function {
               if let Some(ref name) = func.name {
                   entry.function_name = name.clone();
               }
               if let Some(ref args) = func.arguments {
                   entry.arguments.push_str(args);
               }
           }
       }

       /// Check if any tool calls have been accumulated.
       pub fn has_tool_calls(&self) -> bool {
           !self.tool_calls.is_empty()
       }

       /// Finalize accumulated tool calls, parsing arguments as JSON.
       ///
       /// Returns ToolCalls with PROVIDER IDs (not Sentinel IDs).
       /// Caller must use ToolCallIdMapping to generate Sentinel IDs.
       ///
       /// Returns error if any arguments are not valid JSON.
       pub fn finalize(self) -> Result<Vec<(String, ToolCall)>, StreamError> {
           let mut result = Vec::with_capacity(self.tool_calls.len());

           // Sort by index to maintain order
           let mut entries: Vec<_> = self.tool_calls.into_iter().collect();
           entries.sort_by_key(|(idx, _)| *idx);

           for (index, acc) in entries {
               let provider_id = acc.id.ok_or_else(|| {
                   StreamError::ParseError(format!(
                       "Tool call at index {} missing ID",
                       index
                   ))
               })?;

               // Parse arguments as JSON (per CONTEXT.md - fail on malformed)
               let arguments: serde_json::Value = serde_json::from_str(&acc.arguments)
                   .map_err(|e| StreamError::ParseError(format!(
                       "Malformed tool arguments at index {}: {}",
                       index, e
                   )))?;

               let tool_call = ToolCall {
                   id: provider_id.clone(), // Temporary - caller replaces with Sentinel ID
                   call_type: "function".to_string(),
                   function: ToolCallFunction {
                       name: acc.function_name,
                       arguments,
                   },
               };

               result.push((provider_id, tool_call));
           }

           Ok(result)
       }
   }
   ```

4. Add tests:
   - Single tool call accumulation across multiple deltas
   - Multiple parallel tool calls (different indices) accumulate separately
   - finalize() parses arguments as JSON
   - Malformed arguments return StreamError
   - Missing ID returns StreamError
   - Empty accumulator returns empty vec
  </action>
  <verify>
Run `cargo test native::streaming` - all tests pass including accumulator tests
  </verify>
  <done>
ToolCallAccumulator accumulates streaming tool call deltas by index and finalizes with JSON parsing.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate tool calling into chat handler</name>
  <files>src/native_routes/chat.rs</files>
  <action>
Update the chat handler to properly handle tool call responses:

1. Add imports:
   ```rust
   use crate::native::translate::ToolCallIdMapping;
   use crate::native::streaming::ToolCallAccumulator;
   ```

2. Update handle_non_streaming():
   - translate_response now returns (response, mapping) tuple
   - The mapping is needed if this response contains tool_calls and client will submit results
   - For now, the mapping can be discarded since we're not persisting it (results come in next request with full conversation history)
   - Actually, per CONTEXT.md decision: "ID Mapping Persistence for Multi-Turn - store in session for conversation_id requests"

   Decision point: For v1, we can:
   a) Store mapping in session (adds complexity)
   b) Return mapping hint in response header (client passes back)
   c) Trust that client includes tool_calls in conversation history and we re-translate

   For simplicity in v1, choose (c): When client sends tool result, the previous assistant message with tool_calls will be in history. We can extract the original mapping from that.

   This means: Just update the handler to use the new translate_response return type, ignoring the mapping for now.

3. Update handle_streaming():
   - For streaming with tool calls, we need to:
     a) Detect tool call deltas in stream chunks
     b) Accumulate them using ToolCallAccumulator
     c) On stream completion, finalize and generate Sentinel IDs
     d) Emit tool_calls in the final chunk

   This is complex because we're passing through OpenAI's stream format. Two approaches:
   a) Parse each chunk, accumulate tool calls, re-emit with Sentinel IDs
   b) Pass through as-is with provider IDs (simpler, less unified)

   Per CONTEXT.md "Generate Sentinel-specific tool_call_id" - we should use approach (a).

   However, this adds significant complexity to streaming. For v1, we can:
   - Pass through tool call chunks as-is (provider IDs)
   - Document that streaming tool calls use provider IDs
   - Add Sentinel ID translation in a follow-up

   Actually, let's implement it properly:
   - Track ToolCallAccumulator alongside content accumulator
   - Parse each chunk's tool_calls deltas
   - On stream end, generate Sentinel IDs
   - But wait - we can't modify already-sent chunks

   The right approach: For streaming tool calls, we DON'T modify the stream. The Sentinel ID translation happens only in non-streaming responses. For streaming, clients get provider IDs directly.

   Simplification for v1:
   - Non-streaming: Full Sentinel ID translation
   - Streaming: Provider IDs pass through (document this limitation)

4. Update execute_with_retry():
   - Handle new (response, mapping) return type from translate_response

5. Add/update logging:
   - Log when tool_calls are present in response
   - Log tool count

6. Handle any compilation errors from changed translate_response signature.
  </action>
  <verify>
Run `cargo build` - compiles successfully
Run `cargo test` - existing tests pass
  </verify>
  <done>
Chat handler updated to handle tool call responses with proper translate_response return type. Non-streaming uses Sentinel IDs, streaming passes through provider IDs (documented limitation).
  </done>
</task>

<task type="auto">
  <name>Task 3: Add integration tests for tool calling</name>
  <files>tests/integration/native_chat.rs, tests/mocks/openai.rs</files>
  <action>
Add integration tests for the complete tool calling flow:

1. Add mock helpers in tests/mocks/openai.rs:

   ```rust
   /// Mock response with tool_calls
   pub fn mock_tool_call_response(server: &MockServer) {
       Mock::given(method("POST"))
           .and(path("/v1/chat/completions"))
           .respond_with(ResponseTemplate::new(200).set_body_json(json!({
               "id": "chatcmpl-tool-123",
               "object": "chat.completion",
               "created": 1700000000,
               "model": "gpt-4o-mini",
               "choices": [{
                   "index": 0,
                   "message": {
                       "role": "assistant",
                       "content": null,
                       "tool_calls": [{
                           "id": "call_provider_abc123",
                           "type": "function",
                           "function": {
                               "name": "get_weather",
                               "arguments": "{\"location\": \"Boston\"}"
                           }
                       }]
                   },
                   "finish_reason": "tool_calls"
               }],
               "usage": {
                   "prompt_tokens": 50,
                   "completion_tokens": 20,
                   "total_tokens": 70
               }
           })))
           .mount(server)
           .await;
   }
   ```

2. Add test: test_native_chat_with_tools_request
   - Send request with tools array
   - Verify tools translated to OpenAI format in mock
   - Verify response received correctly

3. Add test: test_native_chat_tool_call_response
   - Mock returns tool_calls in response
   - Verify response has tool_calls with Sentinel ID (call_xxx format)
   - Verify arguments are parsed JSON (not string)
   - Verify finish_reason is "tool_calls"

4. Add test: test_native_chat_tool_result_submission
   - Send request with tool result message in history
   - Verify tool result translated to OpenAI tool message format
   - Verify response processed correctly

5. Add test: test_native_chat_invalid_tool_name
   - Send request with tool that has invalid name (e.g., "my-tool" with hyphen)
   - Verify 400 validation error

6. Add test: test_native_chat_empty_tool_description
   - Send request with tool that has empty description
   - Verify 400 validation error

7. Add test: test_native_chat_tool_choice_variants
   - Test auto, none, required, specific function
   - Verify translation to OpenAI format
  </action>
  <verify>
Run `cargo test native_chat` - all tests pass including new tool calling tests
  </verify>
  <done>
Integration tests verify end-to-end tool calling: request translation, response handling with Sentinel IDs, tool result submission, and validation errors.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

```bash
# All streaming tests pass
cargo test native::streaming

# All integration tests pass
cargo test native_chat

# Full test suite passes
cargo test

# Build succeeds
cargo build
```
</verification>

<success_criteria>
- ToolCallAccumulator correctly accumulates streaming deltas by index
- Malformed arguments in streaming fail with descriptive error
- Chat handler handles tool call responses with Sentinel ID translation (non-streaming)
- Integration tests cover: tools in request, tool_calls in response, tool results, validation errors
- All existing tests still pass (no regressions)
- Streaming tool calls documented as passing through provider IDs (v1 limitation)
</success_criteria>

<output>
After completion, create `.planning/phases/05-tool-calling/05-03-SUMMARY.md`
</output>
