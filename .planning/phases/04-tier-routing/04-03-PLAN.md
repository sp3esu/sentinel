---
phase: 04-tier-routing
plan: 03
type: execute
wave: 2
depends_on: ["04-01", "04-01b", "04-02"]
files_modified:
  - src/lib.rs
  - src/native/session.rs
  - src/native_routes/chat.rs
  - tests/integration/native_chat.rs
autonomous: true

must_haves:
  truths:
    - "AppState includes TierRouter and ProviderHealthTracker"
    - "Session struct stores tier alongside provider/model"
    - "Handler resolves model via TierRouter when no existing session"
    - "Handler enforces tier upgrade only (no downgrade) within session"
    - "X-Sentinel-Model and X-Sentinel-Tier response headers set"
    - "Retry once with next model on provider failure"
    - "Existing /v1/* endpoints work unchanged"
  artifacts:
    - path: "src/lib.rs"
      provides: "TierRouter in AppState"
      contains: "tier_router"
    - path: "src/native/session.rs"
      provides: "Session with tier field"
      contains: "pub tier:"
    - path: "src/native_routes/chat.rs"
      provides: "Tier-aware chat handler"
      contains: "tier_router"
    - path: "tests/integration/native_chat.rs"
      provides: "Tier routing integration tests"
      contains: "tier"
  key_links:
    - from: "src/native_routes/chat.rs"
      to: "src/tiers/router.rs"
      via: "Model selection"
      pattern: "tier_router\\.select_model"
    - from: "src/native_routes/chat.rs"
      to: "src/native/session.rs"
      via: "Tier storage in session"
      pattern: "session\\.tier"
---

<objective>
Integrate tier routing into the request handler: wire TierRouter into AppState, add tier to Session, and implement the full routing flow with retry logic.

Purpose: Complete Phase 4 by connecting all tier routing components into the live request flow. This enables clients to use tier-based model selection instead of specifying models directly.

Output: Working tier routing where requests with tier field get appropriate models selected based on cost and availability.
</objective>

<execution_context>
@/Users/gregor/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gregor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-tier-routing/04-CONTEXT.md
@.planning/phases/04-tier-routing/04-RESEARCH.md
@.planning/phases/04-tier-routing/04-01-SUMMARY.md
@.planning/phases/04-tier-routing/04-02-SUMMARY.md

@src/lib.rs
@src/native/session.rs
@src/native_routes/chat.rs
@tests/integration/native_chat.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tier to Session struct</name>
  <files>src/native/session.rs</files>
  <action>
Update the Session struct in `src/native/session.rs` to include the tier:

1. Add import for Tier:
   ```rust
   use crate::native::types::Tier;
   ```

2. Update Session struct:
   ```rust
   /// Session data stored in Redis
   ///
   /// Represents a conversation's provider/model/tier binding for stickiness.
   /// Once a session is created, all subsequent requests in the same
   /// conversation use the same provider and model. Tier can only upgrade.
   #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
   pub struct Session {
       /// Unique session identifier (same as conversation_id)
       pub id: String,
       /// Provider name (e.g., "openai", "anthropic")
       pub provider: String,
       /// Model identifier used for this session
       pub model: String,
       /// Complexity tier for this session
       pub tier: Tier,
       /// User's external ID (for debugging/cleanup)
       pub external_id: String,
       /// Unix timestamp when session was created
       pub created_at: i64,
   }
   ```

3. Update the `create` method signature and implementation:
   ```rust
   /// Create a new session for a conversation
   ///
   /// Stores the provider/model/tier binding in Redis with TTL.
   /// The TTL resets on each activity via `touch()`.
   #[instrument(skip(self), fields(conversation_id = %conversation_id, provider = %provider, model = %model, tier = ?tier))]
   pub async fn create(
       &self,
       conversation_id: &str,
       provider: &str,
       model: &str,
       tier: Tier,
       external_id: &str,
   ) -> AppResult<Session> {
       let session = Session {
           id: conversation_id.to_string(),
           provider: provider.to_string(),
           model: model.to_string(),
           tier,
           external_id: external_id.to_string(),
           created_at: Utc::now().timestamp(),
       };

       let key = keys::session(conversation_id);
       self.cache
           .set_with_ttl(&key, &session, self.session_ttl)
           .await?;

       debug!("Session created");
       Ok(session)
   }
   ```

4. Add method to update session tier (for tier upgrade):
   ```rust
   /// Update session tier, provider, and model for tier upgrade
   ///
   /// Called when a request in an existing session requests a higher tier.
   /// Only upgrades are allowed (simple -> moderate -> complex).
   #[instrument(skip(self), fields(conversation_id = %conversation_id, new_tier = ?new_tier))]
   pub async fn upgrade_tier(
       &self,
       conversation_id: &str,
       provider: &str,
       model: &str,
       new_tier: Tier,
   ) -> AppResult<()> {
       let key = keys::session(conversation_id);

       // Get existing session
       let mut session: Session = self.cache.get::<Session>(&key).await?.ok_or_else(|| {
           crate::error::AppError::NotFound(format!("Session not found: {}", conversation_id))
       })?;

       // Update tier, provider, model
       session.tier = new_tier;
       session.provider = provider.to_string();
       session.model = model.to_string();

       // Save back with TTL refresh
       self.cache
           .set_with_ttl(&key, &session, self.session_ttl)
           .await?;

       debug!("Session tier upgraded");
       Ok(())
   }
   ```

5. Update existing tests and add new tests:
   - Update `test_session_serialization_roundtrip` to include tier
   - Add test for `test_session_with_tier_serializes_correctly`
   - Add test for tier field in JSON format
  </action>
  <verify>
`cargo check` passes.
`cargo test native::session::tests` passes with updated tests.
  </verify>
  <done>
Session struct includes tier field.
SessionManager.create accepts tier parameter.
upgrade_tier method allows tier upgrades.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add TierRouter to AppState</name>
  <files>src/lib.rs</files>
  <action>
Update AppState in `src/lib.rs` to include tier routing components:

1. Add imports:
   ```rust
   pub use crate::tiers::{ProviderHealthTracker, TierConfigCache, TierRouter};
   ```

2. Add fields to AppState struct:
   ```rust
   /// Tier configuration cache for model routing
   pub tier_config_cache: Arc<TierConfigCache>,
   /// Provider health tracker for availability monitoring
   pub health_tracker: Arc<ProviderHealthTracker>,
   /// Tier router for model selection
   pub tier_router: Arc<TierRouter>,
   ```

3. Initialize in `AppState::new()` after session_manager:
   ```rust
   // Initialize tier configuration cache
   let tier_config_cache = Arc::new(TierConfigCache::new(
       redis_cache.clone(),
       zion_client.clone(),
       config.tier_config_ttl_seconds,
   ));

   // Initialize provider health tracker
   let health_tracker = Arc::new(ProviderHealthTracker::new());

   // Initialize tier router
   let tier_router = Arc::new(TierRouter::new(
       tier_config_cache.clone(),
       health_tracker.clone(),
   ));
   ```

   Add to Self { ... }:
   ```rust
   tier_config_cache,
   health_tracker,
   tier_router,
   ```

4. Initialize in `AppState::new_for_testing()`:
   ```rust
   // Create tier config cache with in-memory backend for testing
   let tier_config_cache = Arc::new(TierConfigCache::new_for_testing(
       in_memory_cache.clone(),
       zion_client.clone(),
       60, // 1 minute TTL for tests
   ));

   let health_tracker = Arc::new(ProviderHealthTracker::new());

   let tier_router = Arc::new(TierRouter::new(
       tier_config_cache.clone(),
       health_tracker.clone(),
   ));
   ```

   Add to Self { ... }.
  </action>
  <verify>
`cargo check` passes.
  </verify>
  <done>
AppState contains tier routing components.
Both production and test constructors initialize tier routing.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement tier-aware chat handler</name>
  <files>src/native_routes/chat.rs</files>
  <action>
Rewrite the model resolution logic in `native_chat_completions` to use tier routing:

1. Add imports:
   ```rust
   use crate::{
       native::types::Tier,
       routes::metrics::{
           record_tier_request, record_model_selection, record_provider_failure, record_model_retry
       },
   };
   ```

2. Replace the session handling block with tier-aware logic:

```rust
// Session handling: use stored provider/model or select via tier routing
let requested_tier = native_request.tier.unwrap_or_default();

// Record tier request metric
record_tier_request(&requested_tier.to_string());

let (provider, model, effective_tier) = if let Some(ref conv_id) = native_request.conversation_id {
    // Try to get existing session
    if let Some(session) = state.session_manager.get(conv_id).await.map_err(|e| {
        NativeErrorResponse::internal(format!("Session lookup failed: {}", e))
    })? {
        // Refresh TTL on activity (fire-and-forget, log errors)
        if let Err(e) = state.session_manager.touch(conv_id).await {
            warn!(conversation_id = %conv_id, error = %e, "Failed to refresh session TTL");
        }

        // Check if tier upgrade is requested
        if requested_tier > session.tier {
            // Tier upgrade: select new model for higher tier
            debug!(
                conversation_id = %conv_id,
                session_tier = ?session.tier,
                requested_tier = ?requested_tier,
                "Tier upgrade requested"
            );

            let selected = state.tier_router
                .select_model(requested_tier, Some(&session.provider))
                .await
                .map_err(|e| NativeErrorResponse::from_app_error(e))?;

            // Update session with new tier/provider/model
            state.session_manager.upgrade_tier(
                conv_id,
                &selected.provider,
                &selected.model,
                requested_tier,
            ).await.map_err(|e| {
                NativeErrorResponse::internal(format!("Session upgrade failed: {}", e))
            })?;

            info!(
                conversation_id = %conv_id,
                old_tier = ?session.tier,
                new_tier = ?requested_tier,
                model = %selected.model,
                "Session tier upgraded"
            );

            record_model_selection(&requested_tier.to_string(), &selected.provider, &selected.model);
            (selected.provider, selected.model, requested_tier)
        } else {
            // Same or lower tier: use session model (downgrade not allowed)
            if requested_tier < session.tier {
                debug!(
                    conversation_id = %conv_id,
                    session_tier = ?session.tier,
                    requested_tier = ?requested_tier,
                    "Tier downgrade not allowed, using session tier"
                );
            }
            (session.provider, session.model, session.tier)
        }
    } else {
        // Session expired or never existed - create new session with tier routing
        let selected = state.tier_router
            .select_model(requested_tier, None)
            .await
            .map_err(|e| NativeErrorResponse::from_app_error(e))?;

        // Store new session
        state.session_manager.create(
            conv_id,
            &selected.provider,
            &selected.model,
            requested_tier,
            &user.external_id,
        )
        .await
        .map_err(|e| NativeErrorResponse::internal(format!("Session creation failed: {}", e)))?;

        info!(
            conversation_id = %conv_id,
            tier = ?requested_tier,
            provider = %selected.provider,
            model = %selected.model,
            "Created new session with tier routing"
        );

        record_model_selection(&requested_tier.to_string(), &selected.provider, &selected.model);
        (selected.provider, selected.model, requested_tier)
    }
} else {
    // No conversation_id - fresh selection each time (stateless mode)
    let selected = state.tier_router
        .select_model(requested_tier, None)
        .await
        .map_err(|e| NativeErrorResponse::from_app_error(e))?;

    debug!(
        tier = ?requested_tier,
        provider = %selected.provider,
        model = %selected.model,
        "Stateless tier routing (no conversation_id)"
    );

    record_model_selection(&requested_tier.to_string(), &selected.provider, &selected.model);
    (selected.provider, selected.model, requested_tier)
};
```

3. Add helper method to NativeErrorResponse for AppError conversion:
   In `src/native/error.rs`, add:
   ```rust
   /// Convert from AppError
   pub fn from_app_error(err: crate::error::AppError) -> Self {
       use crate::error::AppError;
       match err {
           AppError::ServiceUnavailable { message, .. } => {
               Self::service_unavailable(&message)
           }
           AppError::BadRequest(msg) => Self::validation(msg),
           AppError::NotFound(msg) => Self::validation(msg),
           _ => Self::internal(err.to_string()),
       }
   }

   /// Service unavailable (503)
   pub fn service_unavailable(message: &str) -> Self {
       Self {
           status: StatusCode::SERVICE_UNAVAILABLE,
           error: NativeErrorBody {
               message: message.to_string(),
               error_type: "service_unavailable".to_string(),
               code: "service_unavailable".to_string(),
               provider: None,
           },
       }
   }
   ```

4. Update the response builder to add headers:
   For non-streaming, after building the response add:
   ```rust
   // Add model/tier headers
   let response = Response::builder()
       .status(StatusCode::OK)
       .header("X-Sentinel-Model", &model)
       .header("X-Sentinel-Tier", effective_tier.to_string())
       .header(header::CONTENT_TYPE, "application/json")
       .body(Body::from(serde_json::to_string(&native_response)?))
       .map_err(|e| NativeErrorResponse::internal(format!("Failed to build response: {}", e)))?;
   ```

   For streaming, add headers to the response builder:
   ```rust
   let response = Response::builder()
       .status(StatusCode::OK)
       .header(header::CONTENT_TYPE, "text/event-stream")
       .header(header::CACHE_CONTROL, "no-cache")
       .header(header::CONNECTION, "keep-alive")
       .header("X-Accel-Buffering", "no")
       .header("X-Sentinel-Model", &model)
       .header("X-Sentinel-Tier", effective_tier.to_string())
       .body(body)
       // ...
   ```

5. Add retry logic on provider failure in `handle_non_streaming`:
   ```rust
   // Forward to OpenAI provider with retry on failure
   let provider_response = match state.ai_provider.chat_completions(provider_request.clone(), headers).await {
       Ok(response) => {
           state.tier_router.record_success(&provider, &model);
           response
       }
       Err(e) => {
           // Record failure and try retry
           state.tier_router.record_failure(&provider, &model);
           record_provider_failure(&provider, &model);

           // Try to get alternative model
           if let Ok(Some(retry)) = state.tier_router.get_retry_model(effective_tier, &model).await {
               info!(
                   failed_model = %model,
                   retry_model = %retry.model,
                   "Retrying with alternative model"
               );
               record_model_retry(&effective_tier.to_string(), &model, &retry.model);

               // Update provider_request with new model
               let mut retry_request = provider_request;
               retry_request["model"] = serde_json::Value::String(retry.model.clone());

               match state.ai_provider.chat_completions(retry_request, headers).await {
                   Ok(response) => {
                       state.tier_router.record_success(&retry.provider, &retry.model);
                       response
                   }
                   Err(retry_err) => {
                       state.tier_router.record_failure(&retry.provider, &retry.model);
                       return Err(NativeErrorResponse::provider_error(
                           format!("Retry also failed: {}", retry_err),
                           &retry.provider,
                       ));
                   }
               }
           } else {
               return Err(NativeErrorResponse::provider_error(e.to_string(), &provider));
           }
       }
   };
   ```

   **Streaming handler note:** Streaming cannot retry mid-stream because the connection
   is already established and chunks may have been sent to the client. For streaming:
   - If the initial connection to the provider fails BEFORE any chunks are sent, retry
     with alternative model (same as non-streaming).
   - If failure occurs AFTER streaming has started (mid-stream), fail fast with error.
     Do NOT attempt retry as partial response has already been sent.

   This fail-fast behavior for mid-stream errors is intentional - the client has already
   received partial data and retrying would result in duplicate/corrupted output.
  </action>
  <verify>
`cargo check` passes.
`cargo test` passes (may need to fix existing tests).
  </verify>
  <done>
Handler uses tier routing for model selection.
Session tier tracking and upgrade logic works.
Retry logic attempts alternative model on failure.
Response headers include X-Sentinel-Model and X-Sentinel-Tier.
  </done>
</task>

<task type="auto">
  <name>Task 4: Update integration tests for tier routing</name>
  <files>tests/integration/native_chat.rs, tests/mocks/zion.rs</files>
  <action>
Update integration tests to use tier routing:

1. Update mock Zion server to return tier config:
   Add to `tests/mocks/zion.rs`:
   ```rust
   /// Mock tier config endpoint
   pub fn mock_tier_config() -> Mock {
       Mock::given(method("GET"))
           .and(path("/api/v1/tiers/config"))
           .respond_with(ResponseTemplate::new(200).set_body_json(json!({
               "success": true,
               "data": {
                   "version": "1.0.0",
                   "updatedAt": "2026-01-01T00:00:00Z",
                   "tiers": {
                       "simple": [{
                           "provider": "openai",
                           "model": "gpt-4o-mini",
                           "relativeCost": 1,
                           "inputPricePerMillion": 0.15,
                           "outputPricePerMillion": 0.60
                       }],
                       "moderate": [{
                           "provider": "openai",
                           "model": "gpt-4o",
                           "relativeCost": 5,
                           "inputPricePerMillion": 2.50,
                           "outputPricePerMillion": 10.00
                       }],
                       "complex": [{
                           "provider": "openai",
                           "model": "gpt-4o",
                           "relativeCost": 5,
                           "inputPricePerMillion": 2.50,
                           "outputPricePerMillion": 10.00
                       }]
                   }
               }
           })))
   }
   ```

2. Update existing tests to use `tier` instead of `model`:
   - Change `"model": "gpt-4"` to `"tier": "simple"`
   - Update assertions as needed

3. Add new tier routing tests to `tests/integration/native_chat.rs`:

   ```rust
   #[tokio::test]
   async fn test_tier_simple_routes_to_gpt4o_mini() {
       // Setup mocks including tier config
       let (mock_openai, mock_zion) = setup_mocks().await;
       mock_tier_config().mount(&mock_zion).await;

       let app = create_test_app(&mock_openai, &mock_zion).await;

       let response = app
           .post("/native/chat/completions")
           .header("Authorization", "Bearer test-jwt")
           .json(&json!({
               "tier": "simple",
               "messages": [{"role": "user", "content": "Hello"}]
           }))
           .await;

       assert_eq!(response.status(), StatusCode::OK);
       // Check response headers
       assert_eq!(response.header("X-Sentinel-Tier"), "simple");
       // Model selected should be gpt-4o-mini (from tier config)
   }

   #[tokio::test]
   async fn test_tier_defaults_to_simple() {
       // Setup mocks
       let (mock_openai, mock_zion) = setup_mocks().await;
       mock_tier_config().mount(&mock_zion).await;

       let app = create_test_app(&mock_openai, &mock_zion).await;

       let response = app
           .post("/native/chat/completions")
           .header("Authorization", "Bearer test-jwt")
           .json(&json!({
               "messages": [{"role": "user", "content": "Hello"}]
           }))
           .await;

       assert_eq!(response.status(), StatusCode::OK);
       assert_eq!(response.header("X-Sentinel-Tier"), "simple");
   }

   #[tokio::test]
   async fn test_session_tier_upgrade() {
       // Setup mocks
       let (mock_openai, mock_zion) = setup_mocks().await;
       mock_tier_config().mount(&mock_zion).await;

       let app = create_test_app(&mock_openai, &mock_zion).await;

       // First request: simple tier
       let response1 = app
           .post("/native/chat/completions")
           .header("Authorization", "Bearer test-jwt")
           .json(&json!({
               "tier": "simple",
               "conversation_id": "upgrade-test",
               "messages": [{"role": "user", "content": "Hello"}]
           }))
           .await;

       assert_eq!(response1.status(), StatusCode::OK);
       assert_eq!(response1.header("X-Sentinel-Tier"), "simple");

       // Second request: upgrade to moderate
       let response2 = app
           .post("/native/chat/completions")
           .header("Authorization", "Bearer test-jwt")
           .json(&json!({
               "tier": "moderate",
               "conversation_id": "upgrade-test",
               "messages": [{"role": "user", "content": "Complex question"}]
           }))
           .await;

       assert_eq!(response2.status(), StatusCode::OK);
       assert_eq!(response2.header("X-Sentinel-Tier"), "moderate");
   }

   #[tokio::test]
   async fn test_session_tier_downgrade_prevented() {
       // Setup mocks
       let (mock_openai, mock_zion) = setup_mocks().await;
       mock_tier_config().mount(&mock_zion).await;

       let app = create_test_app(&mock_openai, &mock_zion).await;

       // First request: moderate tier
       let response1 = app
           .post("/native/chat/completions")
           .header("Authorization", "Bearer test-jwt")
           .json(&json!({
               "tier": "moderate",
               "conversation_id": "downgrade-test",
               "messages": [{"role": "user", "content": "Hello"}]
           }))
           .await;

       assert_eq!(response1.status(), StatusCode::OK);
       assert_eq!(response1.header("X-Sentinel-Tier"), "moderate");

       // Second request: try to downgrade to simple (should stay moderate)
       let response2 = app
           .post("/native/chat/completions")
           .header("Authorization", "Bearer test-jwt")
           .json(&json!({
               "tier": "simple",
               "conversation_id": "downgrade-test",
               "messages": [{"role": "user", "content": "Simple question"}]
           }))
           .await;

       assert_eq!(response2.status(), StatusCode::OK);
       // Should still be moderate (downgrade prevented)
       assert_eq!(response2.header("X-Sentinel-Tier"), "moderate");
   }

   #[tokio::test]
   async fn test_invalid_tier_rejected() {
       let (mock_openai, mock_zion) = setup_mocks().await;

       let app = create_test_app(&mock_openai, &mock_zion).await;

       let response = app
           .post("/native/chat/completions")
           .header("Authorization", "Bearer test-jwt")
           .json(&json!({
               "tier": "invalid_tier",
               "messages": [{"role": "user", "content": "Hello"}]
           }))
           .await;

       // Should fail validation (serde rejects invalid enum)
       assert_eq!(response.status(), StatusCode::BAD_REQUEST);
   }
   ```

4. Ensure existing /v1/* endpoint tests still pass (regression check).
  </action>
  <verify>
`cargo test --test integration native_chat` passes with all tier tests.
`cargo test --test integration` passes (full integration suite).
  </verify>
  <done>
Integration tests verify tier routing works end-to-end.
Session tier upgrade and downgrade prevention tested.
Backward compatibility with tier defaults verified.
  </done>
</task>

<task type="auto">
  <name>Task 5: Verify /v1/* endpoints unchanged</name>
  <files>tests/integration/chat_completions.rs</files>
  <action>
Run existing /v1/* integration tests to ensure they still work:

1. Verify existing tests pass:
   ```bash
   cargo test --test integration chat_completions
   ```

2. If any tests fail due to changes, fix them without changing the /v1/* API behavior.

3. The /v1/* endpoints should:
   - Still accept `model` field (not `tier`)
   - Pass model directly to OpenAI
   - Not use tier routing

4. Add a regression test if not already present:
   ```rust
   #[tokio::test]
   async fn test_v1_endpoints_unchanged() {
       // Verify /v1/chat/completions still works with model field
       let (mock_openai, mock_zion) = setup_mocks().await;

       let app = create_test_app(&mock_openai, &mock_zion).await;

       let response = app
           .post("/v1/chat/completions")
           .header("Authorization", "Bearer test-jwt")
           .json(&json!({
               "model": "gpt-4",
               "messages": [{"role": "user", "content": "Hello"}]
           }))
           .await;

       assert_eq!(response.status(), StatusCode::OK);
   }
   ```
  </action>
  <verify>
`cargo test --test integration` passes (all existing tests).
/v1/* endpoints work unchanged.
  </verify>
  <done>
/v1/* endpoints confirmed working without changes.
Native API uses tier routing, /v1/* uses direct model pass-through.
  </done>
</task>

</tasks>

<verification>
1. `cargo check` - No compilation errors
2. `cargo test native::session::tests` - Session tests pass with tier field
3. `cargo test native::request::tests` - Request tests pass (tier replaces model)
4. `cargo test --test integration native_chat` - Tier routing integration tests pass
5. `cargo test --test integration` - Full integration suite passes
6. `cargo test` - All unit tests pass
7. Manual test (optional): Send request with tier field, verify X-Sentinel-Model header
</verification>

<success_criteria>
- AppState includes TierRouter, ProviderHealthTracker, TierConfigCache
- Session struct stores tier alongside provider/model
- Handler resolves model via TierRouter based on tier
- Session tier upgrade works (simple -> moderate -> complex)
- Session tier downgrade prevented (uses session tier)
- X-Sentinel-Model and X-Sentinel-Tier response headers present
- Retry logic attempts alternative model on failure
- /v1/* endpoints unchanged (regression-free)
- All integration tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/04-tier-routing/04-03-SUMMARY.md`
</output>
