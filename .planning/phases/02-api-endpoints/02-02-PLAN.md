---
phase: 02-api-endpoints
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - tests/integration/native_chat.rs
  - tests/integration/mod.rs
autonomous: true

must_haves:
  truths:
    - "Integration tests verify non-streaming native chat completions"
    - "Integration tests verify streaming native chat completions"
    - "Integration tests verify validation error responses"
    - "All existing /v1/* integration tests pass (regression-free)"
  artifacts:
    - path: "tests/integration/native_chat.rs"
      provides: "Integration tests for /native/v1/chat/completions"
      min_lines: 100
    - path: "tests/integration/mod.rs"
      provides: "Module declaration for native_chat tests"
      contains: "mod native_chat"
  key_links:
    - from: "tests/integration/native_chat.rs"
      to: "tests/common/mod.rs"
      via: "TokenTrackingTestHarness for test setup"
      pattern: "TokenTrackingTestHarness::new"
    - from: "tests/integration/native_chat.rs"
      to: "/native/v1/chat/completions"
      via: "HTTP POST requests"
      pattern: "post.*native/v1/chat/completions"
---

<objective>
Create integration tests for the native chat completions endpoint and verify existing /v1/* endpoints work unchanged.

Purpose: Validate Phase 2 implementation and ensure backward compatibility
Output: Comprehensive test coverage for native API + verified regression-free /v1/* endpoints
</objective>

<execution_context>
@/Users/gregor/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gregor/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Phase context
@.planning/phases/02-api-endpoints/02-CONTEXT.md
@.planning/phases/02-api-endpoints/02-RESEARCH.md

# Implementation from Plan 01
@src/native_routes/mod.rs
@src/native_routes/chat.rs

# Test harness patterns to follow
@tests/common/mod.rs
@tests/integration/chat_completions.rs
@tests/integration/mod.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create native chat integration tests</name>
  <files>tests/integration/native_chat.rs</files>
  <action>
Create comprehensive integration tests for /native/v1/chat/completions:

1. Create `tests/integration/native_chat.rs`

2. Test cases for non-streaming:

```rust
#[tokio::test]
async fn test_native_chat_completions_non_streaming() {
    // Set up harness with mocks
    // Send request with stream: false (or omit - default)
    // Verify: 200 OK, response has choices and usage
}

#[tokio::test]
async fn test_native_chat_completions_with_system_message() {
    // Verify system message is translated correctly
    // Check that order validation works (system first)
}

#[tokio::test]
async fn test_native_chat_completions_missing_model() {
    // Phase 2 requires model field
    // Verify: 400 with NativeErrorResponse format
    // Check error.type = "invalid_request_error"
}

#[tokio::test]
async fn test_native_chat_completions_unknown_field_rejected() {
    // Send request with unknown field (e.g., "foo": "bar")
    // Verify: 400 with validation error (deny_unknown_fields)
}

#[tokio::test]
async fn test_native_chat_completions_unauthorized() {
    // Send request without Authorization header
    // Verify: 401 with NativeErrorResponse format
}
```

3. Test cases for streaming:

```rust
#[tokio::test]
async fn test_native_chat_completions_streaming() {
    // Set up harness with streaming mock
    // Send request with stream: true
    // Verify: 200 OK, Content-Type: text/event-stream
    // Verify: Response contains SSE chunks ending with [DONE]
}

#[tokio::test]
async fn test_native_chat_completions_streaming_usage() {
    // Verify usage is tracked for streaming requests
    // Check batching_tracker receives correct token counts
}
```

4. Test utilities:
   - Use existing `TokenTrackingTestHarness::new().await`
   - Use existing `make_test_profile()` from common
   - Use existing mock methods: `mock_get_user_profile_success`, `mock_chat_completion_with_usage`

5. Error format verification:
   - All errors should match native format: `{"error": {"message": "...", "type": "...", "code": ...}}`
   - NOT OpenAI format with different error.code structure

Pattern from 02-RESEARCH.md:
```rust
let response = harness.server
    .post("/native/v1/chat/completions")
    .add_header("Authorization", format!("Bearer {}", constants::TEST_JWT_TOKEN))
    .json(&json!({
        "messages": [{"role": "user", "content": "Hello!"}],
        "model": "gpt-4o"
    }))
    .await;
```
  </action>
  <verify>`cargo test native_chat` - all new tests pass</verify>
  <done>Native chat integration tests exist and pass</done>
</task>

<task type="auto">
  <name>Task 2: Wire test module and run regression suite</name>
  <files>tests/integration/mod.rs</files>
  <action>
1. Add to `tests/integration/mod.rs`:
   `mod native_chat;`

2. Run full regression test suite:
   `cargo test --test integration`

3. Verify specific existing tests still pass:
   - `test_chat_completions_*` (all tests in chat_completions.rs)
   - `test_models_*` (all tests in models.rs)
   - `test_health_*` (all tests in health.rs)

4. Document any test failures (should be zero if /v1/* is unchanged)

The regression requirement from Success Criteria:
> Existing /v1/* endpoints work unchanged (regression-free)

If any existing test fails, investigate and fix - it means native routes interfered with /v1 routes.
  </action>
  <verify>
1. `cargo test --test integration` - ALL tests pass
2. Specifically: `cargo test --test integration chat_completions` - passes
3. Specifically: `cargo test --test integration models` - passes
  </verify>
  <done>All integration tests pass including native_chat and existing /v1/* regression suite</done>
</task>

<task type="auto">
  <name>Task 3: Add regression marker test</name>
  <files>tests/integration/native_chat.rs</files>
  <action>
Add an explicit regression marker test that documents the /v1/* compatibility requirement:

```rust
/// Regression test: Verify /v1/* endpoints are unaffected by native routes
///
/// This test exists as explicit documentation that adding /native/* routes
/// MUST NOT break existing /v1/* functionality. If this test fails after
/// changes to native_routes, the router configuration is wrong.
#[tokio::test]
async fn test_v1_endpoints_regression_check() {
    let harness = TokenTrackingTestHarness::new().await;
    harness.zion.mock_get_user_profile_success(make_test_profile()).await;
    harness.openai.mock_chat_completion_with_usage("Hello!", 10, 5).await;

    // Verify /v1/chat/completions still works
    let response = harness.server
        .post("/v1/chat/completions")
        .add_header("Authorization", format!("Bearer {}", TEST_JWT_TOKEN))
        .json(&json!({
            "model": "gpt-4o",
            "messages": [{"role": "user", "content": "Hello"}]
        }))
        .await;

    response.assert_status_ok();

    // Also verify native endpoint works (both coexist)
    harness.zion.mock_get_user_profile_success(make_test_profile()).await;
    harness.openai.mock_chat_completion_with_usage("World!", 10, 5).await;

    let native_response = harness.server
        .post("/native/v1/chat/completions")
        .add_header("Authorization", format!("Bearer {}", TEST_JWT_TOKEN))
        .json(&json!({
            "model": "gpt-4o",
            "messages": [{"role": "user", "content": "World"}]
        }))
        .await;

    native_response.assert_status_ok();
}
```

This test serves as:
1. Documentation of the regression requirement
2. Early warning if future changes break compatibility
3. Proof that both /v1/* and /native/* coexist correctly
  </action>
  <verify>`cargo test v1_endpoints_regression_check` passes</verify>
  <done>Explicit regression marker test exists and passes</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `cargo test --test integration` - ALL tests pass
2. Test count verification:
   - New tests: 7-8 tests in native_chat.rs
   - Existing tests: unchanged count in other modules
3. Specific regression checks:
   - `cargo test --test integration chat_completions` - passes (unchanged)
   - `cargo test --test integration models` - passes (unchanged)
   - `cargo test --test integration health` - passes (unchanged)
</verification>

<success_criteria>
- Native chat completions tests cover streaming and non-streaming
- Validation error tests verify NativeErrorResponse format
- All existing /v1/* integration tests pass unchanged
- Explicit regression marker test documents compatibility requirement
- Zero test failures across entire integration suite
</success_criteria>

<output>
After completion, create `.planning/phases/02-api-endpoints/02-02-SUMMARY.md`
</output>
